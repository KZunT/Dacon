{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm \n",
    "\n",
    "class model_MIL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.backbone = models.efficientnet_b0(pretrained=True) # fixed\n",
    "        self.backbone = timm.create_model('resnet50', pretrained=True , num_classes = 1)\n",
    "        self.clf = nn.Sigmoid()\n",
    "        \n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(in_features=1000, out_features=1), # fixed\n",
    "#             #nn.Linear(in_features=1024, out_features=1),\n",
    "#             nn.Sigmoid(),\n",
    "#         )\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.clf(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 불러옴 (fe)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "\n",
    "m = model_MIL()\n",
    "m.load_state_dict(torch.load('C:\\\\Users\\\\sanda\\\\Desktop\\\\dacon\\\\MIL_model_trained.pt'))\n",
    "\n",
    "return_nodes = {\n",
    "    'backbone.global_pool.flatten': 'img_feature',\n",
    "}\n",
    "\n",
    "fe = create_feature_extractor(m, return_nodes=return_nodes)\n",
    "fe.to(device)\n",
    "fe.eval()\n",
    "    \n",
    "print('모델 불러옴 (fe)')\n",
    "# for key,item in res.items():\n",
    "#     print(key)\n",
    "#     print(item.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_T = transforms.Compose([\n",
    "                        \n",
    "                        #transforms.Grayscale(num_output_channels=1),\n",
    "                        #transforms.Resize(image_resize), # (h, w) 순서\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.5), (0.5))\n",
    "\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\sanda\\\\Desktop\\\\dacon\\\\test_imgs_HnE_MIL224\\\\test\\\\False'\n",
    "\n",
    "img_list = glob.glob(path + '\\\\*.'+ 'png')\n",
    "#print(len(img_list))\n",
    "img_name = []\n",
    "\n",
    "for img_link in img_list:\n",
    "    img_name.append(img_link.split('\\\\')[-1].split('.')[0].split('_')[:3][2])\n",
    "    \n",
    "img_name = list(set(img_name))    \n",
    "print(len(img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3ef640357644efb89b17e632abe6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for name in tqdm(img_name):\n",
    "    img_patch = glob.glob(path + '\\\\BC_01_'+ name+ '*.png')\n",
    "    img_patch.sort(key = len)\n",
    "    \n",
    "    result_list = []\n",
    "    \n",
    "    for patch in img_patch:\n",
    "        \n",
    "        #print(patch)\n",
    "        \n",
    "        origin_img = Image.open(patch)\n",
    "\n",
    "        img = valid_T(origin_img)\n",
    "\n",
    "        with torch.no_grad():\n",
    "        \n",
    "            img = img.float().to(device)\n",
    "                 \n",
    "            img = img.unsqueeze(0)\n",
    "        \n",
    "            result = fe(img)\n",
    "        \n",
    "        #print(result['img_feature'].shape)\n",
    "        \n",
    "        result_list.append(result['img_feature'])\n",
    "        \n",
    "    #print(len(result_list))\n",
    "    \n",
    "    output = torch.stack(result_list, 0)\n",
    "    #print(output.shape)\n",
    "    output_np = output.cpu().numpy()\n",
    "    np.save('C:\\\\Users\\\\sanda\\\\Desktop\\\\dacon\\\\img_features\\\\BC_01_'+name+'_img_feature', output_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list = glob.glob('C:\\\\Users\\\\sanda\\\\Desktop\\\\dacon\\\\img_features\\\\*')\n",
    "len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_list = []\n",
    "\n",
    "for fe in feature_list:\n",
    "    fe_np = np.load(fe)\n",
    "    dim_list.append(fe_np.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "242\n",
      "68.9504\n"
     ]
    }
   ],
   "source": [
    "print(min(dim_list)) # 최소 패치\n",
    "print(max(dim_list)) # 최대 패치\n",
    "print(sum(dim_list) / len(dim_list)) # 평균 패치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti_list = glob.glob('C:\\\\Users\\\\sanda\\\\Desktop\\\\dacon\\\\train_imgs\\\\*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "\n",
    "for i in feature_list:\n",
    "    name = i.split('\\\\')[-1]\n",
    "    name = name[:10]\n",
    "    a.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []\n",
    "\n",
    "for t in ti_list:\n",
    "    na = t.split('\\\\')[-1].split('.')[0]\n",
    "    b.append(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(a) , len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(set(b) - set(a)) # 이 이미지 HnE는 거의 비어있다.. 카테고리 1 True 다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_f = np.load('C:\\\\Users\\\\sanda\\\\Desktop\\\\dacon\\\\img_features\\\\BC_01_0003_img_feature.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_f = torch.from_numpy(img_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_f = img_f.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([152, 1, 2048])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = img_f.permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048, 152, 1])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "b = F.adaptive_max_pool2d(a, (1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048, 1, 1])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048, 1])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.squeeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
